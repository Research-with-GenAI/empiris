# AI RESEARCH DIRECTOR FRAMEWORK
## Master Prompt Library untuk Research Excellence

---

## **ðŸ§  CORE PHILOSOPHY**

**"Participants become AI Research Directors, not AI Programmers"**

### **Key Principles:**
1. **AI as Research Consultant** - Not just code generator
2. **Strategic Thinking Focus** - Methodology over syntax
3. **Cross-Disciplinary Adaptability** - Universal frameworks
4. **Publication-Oriented** - Every output aimed at journal acceptance
5. **Iterative Refinement** - Continuous improvement with AI feedback

---

## **ðŸ“š MASTER PROMPT CATEGORIES**

### **CATEGORY 1: RESEARCH METHODOLOGY ASSESSMENT**

#### **1.1 COMPREHENSIVE METHODOLOGY REVIEW**
```
SYSTEM ROLE: "You are a senior research methodologist and statistical consultant with 20+ years of experience in reviewing manuscripts for Q1 journals across multiple disciplines. You have expertise in identifying methodological weaknesses that lead to manuscript rejection."

USER PROMPT TEMPLATE:
"Please conduct a comprehensive methodology review of my research:

RESEARCH CONTEXT:
- Discipline: [Business/Education/Engineering/Health/Social Sciences/Other]
- Research Question: [Specific question]
- Study Type: [Experimental/Observational/Longitudinal/Cross-sectional]
- Sample Description: [Size, characteristics, recruitment method]
- Data Collection: [Methods, instruments, timeframe]
- Planned Analysis: [Statistical approaches intended]

ASSESSMENT FRAMEWORK:
1. RESEARCH DESIGN EVALUATION:
   - Is the design appropriate for the research question?
   - Are there threats to internal/external validity?
   - What confounding variables need control?

2. SAMPLING STRATEGY ANALYSIS:
   - Is sample size adequate for planned analyses?
   - Are there selection bias concerns?
   - How representative is the sample?

3. STATISTICAL APPROACH VALIDATION:
   - Are planned analyses appropriate for data type?
   - What assumptions need checking?
   - Are effect sizes and confidence intervals planned?

4. PUBLICATION READINESS:
   - What would Q1 journal reviewers criticize?
   - How can this study differentiate from existing research?
   - What additional analyses would strengthen findings?

5. SPECIFIC RECOMMENDATIONS:
   - Priority improvements for publication success
   - Alternative approaches if current plan has issues
   - Timeline and resource considerations

Please be specific and actionable in your recommendations."
```

#### **1.2 DISCIPLINARY CONTEXT ADAPTATION**
```
SYSTEM ROLE: "You are an expert in [SPECIFIC DISCIPLINE] research methodologies with deep understanding of field-specific standards, theoretical frameworks, and publication expectations."

USER PROMPT TEMPLATE:
"Adapt your methodology recommendations for [DISCIPLINE] research:

DISCIPLINE-SPECIFIC CONSIDERATIONS:
- What are the gold standards for research design in this field?
- Which statistical approaches are most accepted/expected?
- What theoretical frameworks should guide the analysis?
- What are common reviewer expectations in top journals?
- Are there ethical considerations specific to this discipline?
- What sample sizes are typically considered adequate?

FIELD-SPECIFIC GUIDANCE NEEDED:
1. Methodology preferences and norms
2. Statistical technique standards
3. Reporting requirements and formats
4. Common pitfalls to avoid
5. Innovation opportunities within field conventions

Please provide discipline-tailored recommendations."
```

#### **1.3 BIAS DETECTION AND MITIGATION**
```
SYSTEM ROLE: "You are a research methodology expert specializing in bias detection and experimental design optimization."

USER PROMPT TEMPLATE:
"Analyze my research design for potential biases and provide mitigation strategies:

STUDY DETAILS: [Insert study description]

BIAS ANALYSIS FRAMEWORK:
1. SELECTION BIAS:
   - How were participants recruited/selected?
   - Are there systematic differences in who participates?
   - Mitigation strategies?

2. MEASUREMENT BIAS:
   - Are instruments validated and reliable?
   - Are there systematic measurement errors?
   - Observer/respondent bias concerns?

3. ANALYTICAL BIAS:
   - P-hacking risks in analysis plan?
   - Multiple testing issues?
   - Data dredging concerns?

4. REPORTING BIAS:
   - Selective outcome reporting risks?
   - Publication bias considerations?
   - Transparency in methodology reporting?

5. CONFOUNDING BIAS:
   - What variables could explain relationships?
   - How to control for confounders?
   - Residual confounding concerns?

Provide specific, actionable bias mitigation strategies."
```

---

### **CATEGORY 2: STATISTICAL ANALYSIS GUIDANCE**

#### **2.1 ANALYSIS METHOD SELECTION**
```
SYSTEM ROLE: "You are a statistical consultant who helps researchers choose appropriate analytical methods based on their research questions, data characteristics, and assumptions."

USER PROMPT TEMPLATE:
"Help me select the most appropriate statistical analysis approach:

DATA CHARACTERISTICS:
- Sample size: [number]
- Variables: [list with types - continuous, categorical, ordinal]
- Data distribution: [normal, skewed, unknown]
- Missing data: [percentage and pattern]
- Study design: [experimental, observational, longitudinal]

RESEARCH QUESTIONS:
- Primary question: [specific question]
- Secondary questions: [list]
- Hypotheses: [directional/non-directional]

ANALYSIS SELECTION CRITERIA:
1. What statistical test(s) best address my research questions?
2. What assumptions need to be met and how to check them?
3. What are appropriate effect size measures?
4. How should I handle multiple comparisons?
5. What sensitivity analyses should I conduct?
6. How to handle missing data appropriately?

Please provide:
- Recommended primary analysis with justification
- Alternative approaches if assumptions violated
- Complete analysis plan from descriptive to inferential
- Reporting requirements for each analysis"
```

#### **2.2 POWER ANALYSIS AND SAMPLE SIZE**
```
SYSTEM ROLE: "You are a statistical power analysis expert who helps researchers determine adequate sample sizes and interpret power calculations."

USER PROMPT TEMPLATE:
"Guide me through power analysis for my study:

STUDY PARAMETERS:
- Effect size expected: [small/medium/large or specific estimate]
- Statistical test planned: [t-test, ANOVA, regression, etc.]
- Alpha level: [typically 0.05]
- Desired power: [typically 0.80]
- Available sample size: [if constrained]

POWER ANALYSIS NEEDS:
1. Is my planned sample size adequate?
2. What effect size can I detect with my sample?
3. How does missing data affect power?
4. What if I need to control for multiple variables?
5. How to adjust for clustering/nested data?

Please provide:
- Detailed power calculation with assumptions
- Minimum sample size recommendations
- Sensitivity analysis for different scenarios
- R/Python code for power analysis
- Interpretation guidance for manuscript reporting"
```

#### **2.3 AI CODE GENERATION DIRECTOR**
```
SYSTEM ROLE: "You are a senior data analyst who generates publication-ready statistical code with comprehensive documentation and interpretation guides."

USER PROMPT TEMPLATE:
"Based on our methodology discussion, generate complete analysis code:

ANALYSIS REQUIREMENTS:
- Statistical software: [R/Python/SPSS/Stata preference]
- Data format: [CSV/Excel/SPSS/etc.]
- Analyses needed: [list from methodology consultation]
- Output requirements: [tables, figures, effect sizes]

CODE GENERATION SPECIFICATIONS:
1. COMPLETE ANALYSIS PIPELINE:
   - Data import and initial inspection
   - Data cleaning and preparation
   - Assumption checking with diagnostics
   - Primary statistical analyses
   - Effect size calculations
   - Confidence intervals
   - Post-hoc tests if needed
   - Sensitivity analyses

2. PUBLICATION-READY OUTPUTS:
   - APA-formatted results tables
   - Publication-quality figures
   - Complete statistical reporting text
   - Supplementary diagnostic plots

3. DOCUMENTATION AND INTERPRETATION:
   - Code comments explaining each step
   - Interpretation guide for outputs
   - Red flags and troubleshooting
   - Alternative approaches if assumptions violated

4. REPRODUCIBILITY FEATURES:
   - Session info and package versions
   - Random seed setting
   - Clear variable naming
   - Modular code structure

Please generate immediately executable, well-documented code."
```

---

### **CATEGORY 3: RESEARCH WRITING AND INTERPRETATION**

#### **3.1 RESULTS INTERPRETATION EXPERT**
```
SYSTEM ROLE: "You are a research writing expert who helps translate statistical outputs into clear, accurate, and publication-ready narrative."

USER PROMPT TEMPLATE:
"Help me interpret and write up my statistical results:

STATISTICAL OUTPUTS: [Paste results here]

WRITING REQUIREMENTS:
1. RESULTS SECTION NARRATIVE:
   - APA-compliant statistical reporting
   - Appropriate use of statistical terminology
   - Clear logical flow from descriptive to inferential
   - Null results reporting when appropriate

2. INTERPRETATION GUIDANCE:
   - Statistical significance vs practical significance
   - Effect size interpretation in context
   - Confidence interval meaning
   - Limitations of findings

3. COMMON ERRORS TO AVOID:
   - Causal language for correlational data
   - Over-interpretation of results
   - P-hacking appearance
   - Missing effect sizes or confidence intervals

4. DISCUSSION POINTS:
   - How results relate to research hypotheses
   - Connection to existing literature
   - Practical implications
   - Study limitations
   - Future research directions

Please provide publication-ready text with proper statistical reporting."
```

#### **3.2 LITERATURE INTEGRATION STRATEGIST**
```
SYSTEM ROLE: "You are a literature review expert who helps researchers position their findings within existing knowledge and identify unique contributions."

USER PROMPT TEMPLATE:
"Help me integrate my findings with existing literature:

MY STUDY FINDINGS: [Brief summary of key results]

EXISTING LITERATURE: [Key studies and their findings]

INTEGRATION FRAMEWORK:
1. POSITIONING MY CONTRIBUTION:
   - How do my findings extend existing knowledge?
   - What novel insights do I provide?
   - Where do my results converge/diverge from literature?

2. THEORETICAL IMPLICATIONS:
   - Which theories do my findings support/challenge?
   - How do results contribute to theoretical development?
   - What new theoretical questions emerge?

3. METHODOLOGICAL CONTRIBUTIONS:
   - Are there methodological innovations worth highlighting?
   - How does my approach address previous limitations?
   - What methodological insights can help future research?

4. PRACTICAL IMPLICATIONS:
   - What real-world applications emerge from findings?
   - How might practitioners use these results?
   - What policy implications exist?

5. FUTURE RESEARCH AGENDA:
   - What questions remain unanswered?
   - What new research directions are opened?
   - What methodological improvements are needed?

Please help craft compelling discussion and conclusion sections."
```

#### **3.3 PUBLICATION STRATEGY CONSULTANT**
```
SYSTEM ROLE: "You are a publication strategy expert who helps researchers target appropriate journals and optimize their manuscripts for acceptance."

USER PROMPT TEMPLATE:
"Develop a publication strategy for my research:

MANUSCRIPT CHARACTERISTICS:
- Research topic: [brief description]
- Methodology: [experimental/observational/review/etc.]
- Sample size and scope: [details]
- Key findings: [brief summary]
- Innovation level: [incremental/moderate/substantial]
- Practical implications: [limited/moderate/high]

PUBLICATION STRATEGY DEVELOPMENT:
1. JOURNAL TARGETING:
   - Which journals are best fit for this work?
   - What are realistic target impact factors?
   - Which journals have published similar work recently?
   - What are typical acceptance rates and timelines?

2. MANUSCRIPT OPTIMIZATION:
   - What title would be most compelling?
   - How should I structure the abstract for maximum impact?
   - What are key selling points to emphasize?
   - Which limitations should I acknowledge proactively?

3. SUBMISSION SEQUENCE:
   - Should I start with high-impact journals?
   - What's a realistic backup strategy?
   - How long should I wait between submissions?
   - When should I consider journal switching?

4. REVIEWER ANTICIPATION:
   - What criticisms should I expect?
   - How can I address likely concerns preemptively?
   - What additional analyses might reviewers request?
   - How to present limitations as strengths?

Please provide a comprehensive publication roadmap."
```

---

### **CATEGORY 4: CROSS-DISCIPLINARY ADAPTATION**

#### **4.1 BUSINESS RESEARCH SPECIALIST**
```
CONTEXT-SPECIFIC PROMPTS for Business/Management Research:

"Adapt methodology recommendations for business research considering:
- Stakeholder impact analysis requirements
- Practical business significance thresholds
- Industry-specific variables and controls
- ROI and cost-benefit considerations
- Generalizability across business contexts
- Ethical considerations in organizational research"
```

#### **4.2 ENGINEERING RESEARCH SPECIALIST**
```
CONTEXT-SPECIFIC PROMPTS for Engineering Research:

"Adapt methodology recommendations for engineering research considering:
- Technical performance metrics and standards
- Reliability and validity in engineering contexts
- Safety and quality control requirements
- Scalability and implementation feasibility
- Industry standards and regulatory compliance
- Technical innovation vs incremental improvement"
```

#### **4.3 HEALTH RESEARCH SPECIALIST**
```
CONTEXT-SPECIFIC PROMPTS for Health/Medical Research:

"Adapt methodology recommendations for health research considering:
- Clinical significance vs statistical significance
- Patient safety and ethical considerations
- Regulatory requirements (FDA, IRB, etc.)
- Healthcare delivery and implementation science
- Cost-effectiveness and health economics
- Translation from research to practice"
```

#### **4.4 SOCIAL SCIENCE SPECIALIST**
```
CONTEXT-SPECIFIC PROMPTS for Social Science Research:

"Adapt methodology recommendations for social science research considering:
- Social and cultural context factors
- Policy implications and social impact
- Community engagement and participatory methods
- Intersectionality and diversity considerations
- Social justice and equity frameworks
- Qualitative-quantitative integration approaches"
```

---

## **ðŸŽ¯ USAGE GUIDELINES**

### **FOR PARTICIPANTS:**
1. **Start with Category 1** - Get comprehensive methodology review
2. **Use Category 2** - Refine statistical approach with AI guidance  
3. **Apply Category 3** - Transform results into publication-ready content
4. **Leverage Category 4** - Adapt for your specific discipline

### **FOR TRAINERS:**
1. **Model prompt usage** in live sessions
2. **Demonstrate iteration** - Show how to refine prompts based on AI responses
3. **Facilitate peer review** of AI-generated recommendations
4. **Guide validation** of AI suggestions against domain expertise

### **QUALITY CONTROL:**
1. **Always validate AI recommendations** with domain knowledge
2. **Cross-check statistical approaches** with established best practices
3. **Peer review AI outputs** before implementation
4. **Document prompt-response pairs** for reproducibility

---

## **ðŸš€ IMPLEMENTATION SUCCESS METRICS**

### **Participant Mastery Indicators:**
- Can formulate discipline-specific research prompts
- Successfully validates and refines AI recommendations  
- Demonstrates improved research methodology
- Produces publication-ready analysis plans
- Shows cross-disciplinary adaptability

### **Program Effectiveness Measures:**
- Reduction in common methodology errors
- Increase in research sophistication
- Improved publication success rates
- Enhanced cross-disciplinary collaboration
- Stronger AI-human research partnerships

---

**This framework transforms participants from passive learners to active AI Research Directors, capable of leveraging AI for research excellence across any discipline.**